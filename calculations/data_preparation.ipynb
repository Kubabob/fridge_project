{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371be505",
   "metadata": {},
   "source": [
    "# Data Preparation for YOLO Instance Segmentation\n",
    "\n",
    "This notebook prepares the food-recognition-2022 dataset for training a YOLOv11n-seg model. We will:\n",
    "1. Load and parse the annotations from the JSON files\n",
    "2. Create the YOLO directory structure\n",
    "3. Convert instance segmentation masks to YOLO format\n",
    "4. Create a dataset.yaml file for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972b13f2",
   "metadata": {},
   "source": [
    "## Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef4959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "DATA_ROOT = os.path.join(\"..\", \"datasets\", \"food-recognition-2022\")\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, \"training\")\n",
    "VAL_DIR = os.path.join(DATA_ROOT, \"val\")\n",
    "TEST_DIR = os.path.join(DATA_ROOT, \"test\", \"images\")\n",
    "\n",
    "# Create YOLO dataset directory\n",
    "YOLO_DATASET_DIR = os.path.join(\"..\", \"datasets\", \"yolo_food_dataset\")\n",
    "os.makedirs(YOLO_DATASET_DIR, exist_ok=True)\n",
    "\n",
    "# Define YOLO directory structure\n",
    "for split in [\"train\", \"val\"]:\n",
    "    os.makedirs(os.path.join(YOLO_DATASET_DIR, split, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(YOLO_DATASET_DIR, split, \"labels\"), exist_ok=True)\n",
    "\n",
    "# Verify paths\n",
    "print(f\"Training directory: {TRAIN_DIR}\")\n",
    "print(f\"Validation directory: {VAL_DIR}\")\n",
    "print(f\"YOLO dataset directory: {YOLO_DATASET_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67189391",
   "metadata": {},
   "source": [
    "## Load Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b962c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations from JSON files\n",
    "def load_annotations(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Load train and validation annotations\n",
    "train_annotations = load_annotations(os.path.join(TRAIN_DIR, \"annotations.json\"))\n",
    "val_annotations = load_annotations(os.path.join(VAL_DIR, \"annotations.json\"))\n",
    "\n",
    "# Extract class information and create a class mapping\n",
    "categories = {cat['id']: cat['name'] for cat in train_annotations['categories']}\n",
    "class_ids = {cat_id: idx for idx, cat_id in enumerate(categories.keys())}\n",
    "\n",
    "print(f\"Found {len(categories)} categories:\")\n",
    "for cat_id, name in categories.items():\n",
    "    print(f\"  {class_ids[cat_id]}: {name} (original id: {cat_id})\")\n",
    "\n",
    "print(f\"\\nTraining images: {len(train_annotations['images'])}\")\n",
    "print(f\"Validation images: {len(val_annotations['images'])}\")\n",
    "print(f\"Training annotations: {len(train_annotations['annotations'])}\")\n",
    "print(f\"Validation annotations: {len(val_annotations['annotations'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dea466",
   "metadata": {},
   "source": [
    "## Process Annotations\n",
    "\n",
    "Convert the COCO format annotations to YOLO format:\n",
    "- YOLO expects one text file per image in the \"labels\" directory\n",
    "- Each line in the text file represents one object: `class_id x_center y_center width height x1 y1 x2 y2 ... xn yn`\n",
    "- The first 5 values are the class ID and normalized bounding box coordinates (center_x, center_y, width, height)\n",
    "- The remaining values are normalized polygon points of the segmentation mask (x1, y1, x2, y2, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(annotations, src_dir, dest_images_dir, dest_labels_dir):\n",
    "    # Create image_id to filename mapping\n",
    "    image_dict = {img['id']: img for img in annotations['images']}\n",
    "    \n",
    "    # Group annotations by image_id\n",
    "    image_annotations = {}\n",
    "    for ann in annotations['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        if image_id not in image_annotations:\n",
    "            image_annotations[image_id] = []\n",
    "        image_annotations[image_id].append(ann)\n",
    "    \n",
    "    # Process each image\n",
    "    for image_id, anns in tqdm(image_annotations.items(), desc=\"Processing images\"):\n",
    "        image_info = image_dict[image_id]\n",
    "        filename = image_info['file_name']\n",
    "        \n",
    "        # Get image dimensions\n",
    "        img_width = image_info['width']\n",
    "        img_height = image_info['height']\n",
    "        \n",
    "        # Copy image to destination\n",
    "        src_path = os.path.join(src_dir, filename)\n",
    "        dest_path = os.path.join(dest_images_dir, filename)\n",
    "        shutil.copy(src_path, dest_path)\n",
    "        \n",
    "        # Create YOLO annotation file\n",
    "        label_lines = []\n",
    "        \n",
    "        for ann in anns:\n",
    "            category_id = ann['category_id']\n",
    "            yolo_class_id = class_ids[category_id]\n",
    "            \n",
    "            # Convert bbox to YOLO format (normalized x_center, y_center, width, height)\n",
    "            x, y, w, h = ann['bbox']\n",
    "            x_center = (x + w/2) / img_width\n",
    "            y_center = (y + h/2) / img_height\n",
    "            width = w / img_width\n",
    "            height = h / img_height\n",
    "            \n",
    "            # Convert segmentation polygon to YOLO format (normalized coordinates)\n",
    "            if isinstance(ann['segmentation'], list) and len(ann['segmentation']) > 0:\n",
    "                polygon = ann['segmentation'][0]  # Take the first polygon if there are multiple\n",
    "                points = []\n",
    "                for i in range(0, len(polygon), 2):\n",
    "                    x_coord = polygon[i] / img_width\n",
    "                    y_coord = polygon[i+1] / img_height\n",
    "                    points.extend([x_coord, y_coord])\n",
    "                \n",
    "                # Create YOLO format line\n",
    "                line = f\"{yolo_class_id} {x_center} {y_center} {width} {height}\"\n",
    "                for p in points:\n",
    "                    line += f\" {p}\"\n",
    "                label_lines.append(line)\n",
    "        \n",
    "        # Write label file\n",
    "        if label_lines:\n",
    "            label_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "            with open(os.path.join(dest_labels_dir, label_filename), 'w') as f:\n",
    "                f.write('\\n'.join(label_lines))\n",
    "\n",
    "# Process training and validation datasets\n",
    "print(\"Processing training dataset...\")\n",
    "process_dataset(train_annotations, os.path.join(TRAIN_DIR, \"images\"), \n",
    "                os.path.join(YOLO_DATASET_DIR, \"train\", \"images\"), \n",
    "                os.path.join(YOLO_DATASET_DIR, \"train\", \"labels\"))\n",
    "\n",
    "print(\"Processing validation dataset...\")\n",
    "process_dataset(val_annotations, os.path.join(VAL_DIR, \"images\"), \n",
    "                os.path.join(YOLO_DATASET_DIR, \"val\", \"images\"), \n",
    "                os.path.join(YOLO_DATASET_DIR, \"val\", \"labels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b66673",
   "metadata": {},
   "source": [
    "## Create Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bea597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset.yaml for YOLO training\n",
    "yaml_content = f\"\"\"# YOLO Food Recognition Dataset\n",
    "path: {YOLO_DATASET_DIR}\n",
    "train: train/images\n",
    "val: val/images\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "\"\"\"\n",
    "\n",
    "for cat_id, name in sorted([(class_ids[k], v) for k, v in categories.items()]):\n",
    "    yaml_content += f\"  {cat_id}: '{name}'\\n\"\n",
    "\n",
    "# Write YAML file\n",
    "yaml_path = os.path.join(YOLO_DATASET_DIR, \"dataset.yaml\")\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"Dataset configuration saved to {yaml_path}\")\n",
    "print(\"Sample of the YAML file:\")\n",
    "print(\"\\n\".join(yaml_content.split(\"\\n\")[:10]) + \"\\n...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e31412",
   "metadata": {},
   "source": [
    "## Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count files in dataset directories\n",
    "train_images = len(list(Path(os.path.join(YOLO_DATASET_DIR, \"train\", \"images\")).glob(\"*\")))\n",
    "train_labels = len(list(Path(os.path.join(YOLO_DATASET_DIR, \"train\", \"labels\")).glob(\"*.txt\")))\n",
    "val_images = len(list(Path(os.path.join(YOLO_DATASET_DIR, \"val\", \"images\")).glob(\"*\")))\n",
    "val_labels = len(list(Path(os.path.join(YOLO_DATASET_DIR, \"val\", \"labels\")).glob(\"*.txt\")))\n",
    "\n",
    "print(f\"Train images: {train_images}\")\n",
    "print(f\"Train labels: {train_labels}\")\n",
    "print(f\"Validation images: {val_images}\")\n",
    "print(f\"Validation labels: {val_labels}\")\n",
    "\n",
    "# Sample a few labels to verify\n",
    "def sample_label(labels_dir, n=3):\n",
    "    label_files = list(Path(labels_dir).glob(\"*.txt\"))\n",
    "    if not label_files:\n",
    "        return \"No label files found\"\n",
    "    \n",
    "    samples = []\n",
    "    for i in range(min(n, len(label_files))):\n",
    "        with open(label_files[i], 'r') as f:\n",
    "            content = f.read().strip()\n",
    "            samples.append(f\"File: {label_files[i].name}\\n{content[:300]}{'...' if len(content) > 300 else ''}\")\n",
    "    return \"\\n\\n\".join(samples)\n",
    "\n",
    "print(\"\\nSample training labels:\")\n",
    "print(sample_label(os.path.join(YOLO_DATASET_DIR, \"train\", \"labels\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d862b1f",
   "metadata": {},
   "source": [
    "## Visualize Sample Annotations\n",
    "\n",
    "Let's visualize some images with their annotations to verify the conversion was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d96b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_yolo_annotations(image_path, label_path):\n",
    "    # Load image\n",
    "    img = Image.open(image_path)\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Load labels\n",
    "    if not os.path.exists(label_path):\n",
    "        ax.set_title(f\"Image: {os.path.basename(image_path)}\\nNo annotations found\")\n",
    "        return fig\n",
    "    \n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Draw each annotation\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        class_id = int(parts[0])\n",
    "        class_name = next((v for k, v in categories.items() if class_ids[k] == class_id), f\"Class {class_id}\")\n",
    "        \n",
    "        # Bounding box (normalized xywh -> pixel xyxy)\n",
    "        x_center, y_center, width, height = map(float, parts[1:5])\n",
    "        x_min = (x_center - width/2) * img_width\n",
    "        y_min = (y_center - height/2) * img_height\n",
    "        box_width = width * img_width\n",
    "        box_height = height * img_height\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x_min, y_min), box_width, box_height,\n",
    "                            fill=False, edgecolor='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x_min, y_min, class_name, color='white',\n",
    "                bbox=dict(facecolor='red', alpha=0.5))\n",
    "        \n",
    "        # Draw segmentation polygon if available\n",
    "        if len(parts) > 5:\n",
    "            poly_points = parts[5:]\n",
    "            polygon = []\n",
    "            for i in range(0, len(poly_points), 2):\n",
    "                x = float(poly_points[i]) * img_width\n",
    "                y = float(poly_points[i+1]) * img_height\n",
    "                polygon.append((x, y))\n",
    "            \n",
    "            poly_xs, poly_ys = zip(*polygon)\n",
    "            ax.plot(poly_xs, poly_ys, '-', color='lime', linewidth=2)\n",
    "    \n",
    "    ax.set_title(f\"Image: {os.path.basename(image_path)}\")\n",
    "    ax.axis('off')\n",
    "    return fig\n",
    "\n",
    "# Visualize a few random examples\n",
    "def visualize_random_samples(split=\"train\", n=3):\n",
    "    images_dir = os.path.join(YOLO_DATASET_DIR, split, \"images\")\n",
    "    labels_dir = os.path.join(YOLO_DATASET_DIR, split, \"labels\")\n",
    "    \n",
    "    image_files = list(Path(images_dir).glob(\"*\"))\n",
    "    if not image_files:\n",
    "        print(f\"No images found in {images_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Sample n random images\n",
    "    import random\n",
    "    sample_images = random.sample(image_files, min(n, len(image_files)))\n",
    "    \n",
    "    for img_path in sample_images:\n",
    "        base_name = os.path.splitext(img_path.name)[0]\n",
    "        label_path = os.path.join(labels_dir, f\"{base_name}.txt\")\n",
    "        fig = draw_yolo_annotations(img_path, label_path)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"Visualizing training samples:\")\n",
    "visualize_random_samples(\"train\", 3)\n",
    "\n",
    "print(\"Visualizing validation samples:\")\n",
    "visualize_random_samples(\"val\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91652fe8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has:\n",
    "1. Converted the food recognition dataset from COCO format to YOLO format\n",
    "2. Created the proper directory structure for training\n",
    "3. Generated a dataset.yaml file with class information\n",
    "4. Verified the conversion with visualizations\n",
    "\n",
    "Your dataset is now ready for training with YOLOv11n-seg. You can use the training code provided above to start training your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fridge_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
